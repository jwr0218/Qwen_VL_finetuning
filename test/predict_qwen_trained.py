"""
Vision Language Model ì˜ˆì¸¡ ë° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ì›¹íˆ° ìˆœì°¨ ì¶”ë¡  ë²„ì „)

ì´ ëª¨ë“ˆì€ íŒŒì¸íŠœë‹ëœ Qwen2.5-VL ëª¨ë¸ì˜ ì˜ˆì¸¡ ë° í‰ê°€ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
ì›¹íˆ° ì´ë¯¸ì§€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë¶„ì„í•˜ë©° ì´ì „ ì»¨í…ìŠ¤íŠ¸ë¥¼ ëˆ„ì í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.

ì‘ì„±ì: Assistant
Year: 2025
Month: 9
Day: 17
"""

import gc
import json
import logging
import os
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union
from datetime import datetime
import re

import numpy as np
import torch
from datasets import load_dataset
from qwen_vl_utils import process_vision_info
from tqdm import tqdm
from transformers import (
    AutoProcessor,
    Qwen2_5_VLForConditionalGeneration,
)
from PIL import Image

# í‰ê°€ ì§€í‘œ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from rouge import Rouge
from bert_score import score as bert_score
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from nltk.translate.meteor_score import meteor_score
from nltk import word_tokenize, download
import evaluate
from sklearn.metrics import accuracy_score, f1_score
import pandas as pd

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ
try:
    download('punkt')
    download('wordnet')
except:
    pass


@dataclass
class TestConfig:
    """í…ŒìŠ¤íŠ¸ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” ë°ì´í„°í´ë˜ìŠ¤"""
    
    # ë°ì´í„° ê²½ë¡œ
    test_data_path: str = '/workspace/Toonspace_VLM/data/grok_json_file/webtoon_balanced_test.json'
    
    # ëª¨ë¸ ê²½ë¡œ (íŒŒì¸íŠœë‹ëœ ëª¨ë¸)
    model_path: str = '/workspace/Toonspace_VLM/ex_models/with_previous_toptoon_data_grok/checkpoint-10000'
    
    # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
    output_dir: str = 'evaluation_results'
    predictions_file: str = 'predictions.json'
    metrics_file: str = 'evaluation_metrics.json'
    
    # ë°°ì¹˜ ì„¤ì •
    batch_size: int = 1
    max_samples: Optional[int] = None  # Noneì´ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©
    
    # ìƒì„± ì„¤ì •
    max_new_tokens: int = 1024
    temperature: float = 0.7
    top_p: float = 0.9
    do_sample: bool = True
    
    # í”„ë¡œì„¸ì„œ ì„¤ì •
    min_pixels: int = 256 * 28 * 28
    max_pixels: int = 960 * 28 * 28
    
    # í‰ê°€ ì„¤ì •
    compute_bertscore: bool = True
    compute_json_metrics: bool = True  # JSON êµ¬ì¡° í‰ê°€
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€
    system_message: str = field(default="""
    ë‹¹ì‹ ì€ ì›¹íˆ° ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì„±ì¸ ì›¹íˆ° ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì¥ë©´ë³„ë¡œ íš¨ê³¼ìŒ, ë§í’ì„ , ì„œì‚¬ì  ë§¥ë½ì„ ì •í™•íˆ ì¶”ì¶œí•˜ê³ , JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“  í…ìŠ¤íŠ¸ ìš”ì†Œ(ëŒ€ì‚¬, íš¨ê³¼ìŒ, ë‚˜ë ˆì´ì…˜)ë¥¼ í•œêµ­ì–´ë¡œ ì¶”ì¶œí•˜ê³ , ìºë¦­í„° ê´€ê³„ì™€ ìƒí™© ë§¥ë½ì„ ì„¸ë°€íˆ ë¶„ì„í•˜ë©°, ì˜¤í•´ì„ì„ ìµœì†Œí™”í•˜ì‹­ì‹œì˜¤
    """)


@dataclass
class WebtoonPredictConfig:
    """ì›¹íˆ° í´ë” ì˜ˆì¸¡ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” ë°ì´í„°í´ë˜ìŠ¤"""
    
    # ëª¨ë¸ ê²½ë¡œ
    model_path: str = '/workspace/Toonspace_VLM/ex_models/with_previous_toptoon_data_grok/checkpoint-10000'
    
    # ì›ë³¸ ëª¨ë¸ ID (í”„ë¡œì„¸ì„œ ë¡œë“œìš©)
    base_model_id: str = "Qwen/Qwen2-VL-7B-Instruct"  # ë˜ëŠ” "huihui-ai/Qwen2.5-VL-7B-Instruct-abliterated"
    
    # ì…ë ¥ í´ë” ê²½ë¡œ
    image_folder: str = '/workspace/Toonspace_VLM/webtoon_images'
    
    # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
    output_dir: str = 'webtoon_predictions'
    output_file: str = 'sequential_predictions.json'
    
    # ìƒì„± ì„¤ì •
    max_new_tokens: int = 1024
    temperature: float = 0.7
    top_p: float = 0.9
    do_sample: bool = True
    
    # í”„ë¡œì„¸ì„œ ì„¤ì •
    min_pixels: int = 256 * 28 * 28
    max_pixels: int = 960 * 28 * 28
    
    # ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
    use_previous_context: bool = True  # ì´ì „ ì¶”ë¡  ê²°ê³¼ë¥¼ ë‹¤ìŒ ì¶”ë¡ ì— ì‚¬ìš©
    max_context_length: int = 2000  # ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ (í† í° ìˆ˜)
    context_summary_length: int = 500  # ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ê¸¸ì´
    
    # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ì
    image_extensions: List[str] = field(default_factory=lambda: ['.jpg', '.jpeg', '.png', '.webp'])
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    base_prompt: str = "ì´ ì›¹íˆ° ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ëŒ€ì‚¬, íš¨ê³¼ìŒ, ìºë¦­í„° í–‰ë™, ê°ì •ì„ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”."
    
    context_prompt_template: str = """ì´ì „ ì¥ë©´ ìš”ì•½:
{previous_context}

í˜„ì¬ ì´ë¯¸ì§€ë¥¼ ìœ„ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”. ì´ ì›¹íˆ° ì´ë¯¸ì§€ì˜ ëŒ€ì‚¬, íš¨ê³¼ìŒ, ìºë¦­í„° í–‰ë™, ê°ì •ì„ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”."""
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€
    system_message: str = field(default="""
    ë‹¹ì‹ ì€ ì›¹íˆ° ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì›¹íˆ°ì˜ ì—°ì†ëœ ì¥ë©´ì„ ë¶„ì„í•˜ì—¬ ìŠ¤í† ë¦¬ì˜ íë¦„ì„ ì´í•´í•˜ê³ , 
    ê° ì¥ë©´ì˜ ëŒ€ì‚¬, íš¨ê³¼ìŒ, ìºë¦­í„°ì˜ í–‰ë™ê³¼ ê°ì •, ì„œì‚¬ì  ë§¥ë½ì„ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤. 
    ì´ì „ ì¥ë©´ì˜ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ í˜„ì¬ ì¥ë©´ì„ ë” ì •í™•í•˜ê²Œ í•´ì„í•˜ê³ , 
    ëª¨ë“  ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.
    """)


class WebtoonSequentialPredictor:
    """ì›¹íˆ° ì´ë¯¸ì§€ ìˆœì°¨ ì˜ˆì¸¡ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, config: WebtoonPredictConfig):
        self.config = config
        self.setup_logging()
        self.model = None
        self.processor = None
        self.context_history = []  # ì´ì „ ì¶”ë¡  ê²°ê³¼ ì €ì¥
        
    def setup_logging(self) -> None:
        """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
        os.makedirs(self.config.output_dir, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'{self.config.output_dir}/webtoon_prediction.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def clear_memory(self) -> None:
        """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
    
    def load_model_and_processor(self) -> None:
        """íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ"""
        try:
            self.logger.info(f"ëª¨ë¸ ë¡œë“œ ì‹œì‘: {self.config.model_path}")
            
            # ë¡œì»¬ ê²½ë¡œ í™•ì¸ ë° ëª¨ë¸ ë¡œë“œ
            if os.path.exists(self.config.model_path):
                self.logger.info("ë¡œì»¬ ëª¨ë¸ íŒŒì¼ ê°ì§€ë¨")
                
                # ëª¨ë¸ ë¡œë“œ
                self.model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
                    self.config.model_path,
                    device_map="auto",
                    torch_dtype=torch.bfloat16,
                    trust_remote_code=True,
                    local_files_only=True
                )
                self.logger.info(f"ì›ë³¸ ëª¨ë¸({self.config.base_model_id})ì—ì„œ í”„ë¡œì„¸ì„œ ë¡œë“œ")
                self.processor = AutoProcessor.from_pretrained(
                    self.config.base_model_id,
                    min_pixels=self.config.min_pixels,
                    max_pixels=self.config.max_pixels,
                    trust_remote_code=True
                )

            
            self.model.eval()
            self.logger.info("ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.logger.error("ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ base_model_idë¥¼ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            raise
    
    def get_sorted_image_files(self, folder_path: str) -> List[Path]:
        """í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì •ë ¬ëœ ìˆœì„œë¡œ ê°€ì ¸ì˜¤ê¸°"""
        folder = Path(folder_path)
        if not folder.exists():
            raise FileNotFoundError(f"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
        
        image_files = []
        for ext in self.config.image_extensions:
            image_files.extend(folder.glob(f'*{ext}'))
            image_files.extend(folder.glob(f'*{ext.upper()}'))
        
        # íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬ (ìˆ«ìê°€ í¬í•¨ëœ ê²½ìš° ìì—°ìŠ¤ëŸ¬ìš´ ì •ë ¬)
        def natural_sort_key(path):
            """ìì—°ìŠ¤ëŸ¬ìš´ ì •ë ¬ì„ ìœ„í•œ í‚¤ í•¨ìˆ˜"""
            text = path.name
            return [int(c) if c.isdigit() else c.lower() for c in re.split(r'(\d+)', text)]
        
        image_files.sort(key=natural_sort_key)
        
        self.logger.info(f"ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬")
        return image_files
    
    def extract_key_info_from_prediction(self, prediction: str) -> str:
        """ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ ë° ìš”ì•½"""
        try:
            # JSON íŒŒì‹± ì‹œë„
            pred_json = json.loads(prediction)
            
            summary_parts = []
            
            # ëŒ€ì‚¬ ì¶”ì¶œ
            if 'dialogues' in pred_json:
                dialogues = pred_json['dialogues']
                if isinstance(dialogues, list) and dialogues:
                    dialogue_text = ', '.join([d.get('text', '') for d in dialogues[:3]])
                    summary_parts.append(f"ëŒ€ì‚¬: {dialogue_text}")
            
            # ìºë¦­í„° í–‰ë™ ì¶”ì¶œ
            if 'characters' in pred_json:
                characters = pred_json['characters']
                if isinstance(characters, list) and characters:
                    char_actions = ', '.join([c.get('action', '') for c in characters[:2] if 'action' in c])
                    if char_actions:
                        summary_parts.append(f"í–‰ë™: {char_actions}")
            
            # ê°ì • ì¶”ì¶œ
            if 'emotions' in pred_json:
                emotions = pred_json['emotions']
                if isinstance(emotions, list):
                    emotion_text = ', '.join(emotions[:3])
                    summary_parts.append(f"ê°ì •: {emotion_text}")
            
            # ì¥ë©´ ì„¤ëª… ì¶”ì¶œ
            if 'scene_description' in pred_json:
                scene = pred_json['scene_description'][:100]
                summary_parts.append(f"ì¥ë©´: {scene}")
            
            return ' | '.join(summary_parts)
            
        except json.JSONDecodeError:
            # JSONì´ ì•„ë‹Œ ê²½ìš° í…ìŠ¤íŠ¸ ìš”ì•½
            return prediction[:self.config.context_summary_length]
        except Exception as e:
            self.logger.debug(f"ìš”ì•½ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return prediction[:self.config.context_summary_length]
    
    def build_context_prompt(self, base_query: str) -> str:
        """ì´ì „ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        if not self.config.use_previous_context or not self.context_history:
            return base_query
        
        # ìµœê·¼ 3ê°œ ì •ë„ì˜ ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš© (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        recent_context = self.context_history[-3:]
        context_summary = "\n".join([f"ì¥ë©´ {i+1}: {ctx}" for i, ctx in enumerate(recent_context)])
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
        if len(context_summary) > self.config.max_context_length:
            context_summary = context_summary[-self.config.max_context_length:]
        
        return self.config.context_prompt_template.format(
            previous_context=context_summary
        )
    
    @torch.no_grad()
    def predict_single_image(self, image_path: Path, with_context: bool = True) -> Dict[str, Any]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡"""
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        if with_context and self.context_history:
            query = self.build_context_prompt(self.config.base_prompt)
        else:
            query = self.config.base_prompt
        
        # ë©”ì‹œì§€ í¬ë§·íŒ…
        # ë©”ì‹œì§€ í¬ë§·íŒ…
        query = 'ì´ ì›¹íˆ° ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ê³  ì¶”ì¶œí•´ì£¼ì„¸ìš”.'
        messages = [
            {
                "role": "system",
                "content": self.config.system_message,  # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ë¬¸ìì—´ë¡œ!
            },
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": str(image_path)},
                    {"type": "text", "text": query},
                ],
            },
        ]
        
        # í…ìŠ¤íŠ¸ ìƒì„±
        # print(messages)
        
        text = self.processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = self.processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        )
        
        # ìƒì„±
        start_time = time.time()
        generated_ids = self.model.generate(
            **inputs,
            max_new_tokens=self.config.max_new_tokens,
            temperature=self.config.temperature,
            top_p=self.config.top_p,
            do_sample=self.config.do_sample,
        )
        generation_time = time.time() - start_time
        
        # ìƒì„±ëœ í† í°ë§Œ ì¶”ì¶œ
        generated_ids_trimmed = [
            out_ids[len(in_ids):] 
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        
        # ë””ì½”ë”©
        output_text = self.processor.batch_decode(
            generated_ids_trimmed, 
            skip_special_tokens=True, 
            clean_up_tokenization_spaces=False
        )[0]
        
        return {
            'image_path': str(image_path),
            'image_name': image_path.name,
            'query': query,
            'prediction': output_text,
            'generation_time': generation_time,
            'used_context': with_context and bool(self.context_history),
            'context_length': len(self.context_history)
        }
            
    
    def predict_folder(self, folder_path: str = None) -> List[Dict[str, Any]]:
        """í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì˜ˆì¸¡"""
        if folder_path is None:
            folder_path = self.config.image_folder
        
        self.logger.info(f"í´ë” ì˜ˆì¸¡ ì‹œì‘: {folder_path}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        image_files = self.get_sorted_image_files(folder_path)
        if not image_files:
            self.logger.warning("ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_model_and_processor()
        
        # ê²°ê³¼ ì €ì¥
        all_results = []
        self.context_history = []  # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
        
        # ìˆœì°¨ì ìœ¼ë¡œ ì´ë¯¸ì§€ ì²˜ë¦¬
        for idx, image_path in enumerate(tqdm(image_files, desc="Processing images")):
            # self.logger.info(f"ì²˜ë¦¬ ì¤‘ ({idx+1}/{len(image_files)}): {image_path.name}")
            
            # í˜„ì¬ ì´ë¯¸ì§€ ì˜ˆì¸¡
            result = self.predict_single_image(
                image_path, 
                with_context=(idx > 0 and self.config.use_previous_context)
            )
            
            # ê²°ê³¼ì— ìˆœì„œ ì •ë³´ ì¶”ê°€
            result['sequence_number'] = idx + 1
            result['total_images'] = len(image_files)
            
            # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            if 'prediction' in result and self.config.use_previous_context:
                context_summary = self.extract_key_info_from_prediction(result['prediction'])
                self.context_history.append(context_summary)
                
                # ì»¨í…ìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
                if len(self.context_history) > 5:
                    self.context_history.pop(0)
            
            all_results.append(result)
            
            # ì£¼ê¸°ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì •ë¦¬
            if (idx + 1) % 10 == 0:
                self.clear_memory()
                self.logger.info(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ ({idx+1}/{len(image_files)})")
        
        # ê²°ê³¼ ì €ì¥
        self.save_results(all_results, folder_path)
        
        self.logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: ì´ {len(all_results)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬")
        return all_results
    
    def save_results(self, results: List[Dict[str, Any]], source_folder: str) -> None:
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        output_data = {
            'metadata': {
                'source_folder': source_folder,
                'model_path': self.config.model_path,
                'total_images': len(results),
                'timestamp': datetime.now().isoformat(),
                'config': {
                    'use_previous_context': self.config.use_previous_context,
                    'max_context_length': self.config.max_context_length,
                    'temperature': self.config.temperature,
                    'top_p': self.config.top_p
                }
            },
            'predictions': results
        }
        
        # JSON ì €ì¥
        output_path = os.path.join(self.config.output_dir, self.config.output_file)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        # CSV ì €ì¥ (ì„ íƒì )
        df_data = []
        for r in results:
            df_data.append({
                'sequence': r.get('sequence_number'),
                'image_name': r.get('image_name'),
                'prediction': r.get('prediction', ''),
                'generation_time': r.get('generation_time', 0),
                'used_context': r.get('used_context', False),
                'error': r.get('error', '')
            })
        
        df = pd.DataFrame(df_data)
        csv_path = os.path.join(self.config.output_dir, 'sequential_predictions.csv')
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        # í†µê³„ ì¶œë ¥
        self.print_statistics(results)
        
        self.logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
    
    def print_statistics(self, results: List[Dict[str, Any]]) -> None:
        """ì˜ˆì¸¡ í†µê³„ ì¶œë ¥"""
        total = len(results)
        successful = sum(1 for r in results if 'error' not in r)
        failed = total - successful
        
        generation_times = [r.get('generation_time', 0) for r in results if 'generation_time' in r]
        avg_time = np.mean(generation_times) if generation_times else 0
        
        context_used = sum(1 for r in results if r.get('used_context', False))
        
        self.logger.info("\n" + "="*50)
        self.logger.info("ì˜ˆì¸¡ í†µê³„")
        self.logger.info("="*50)
        self.logger.info(f"ì´ ì´ë¯¸ì§€ ìˆ˜: {total}")
        self.logger.info(f"ì„±ê³µ: {successful}")
        self.logger.info(f"ì‹¤íŒ¨: {failed}")
        self.logger.info(f"í‰ê·  ìƒì„± ì‹œê°„: {avg_time:.2f}ì´ˆ")
        self.logger.info(f"ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©: {context_used}/{total}")
        self.logger.info("="*50 + "\n")


class VLMEvaluator:
    """Vision Language Model í‰ê°€ë¥¼ ìœ„í•œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: TestConfig):
        self.config = config
        self.setup_logging()
        self.model = None
        self.processor = None
        self.rouge = Rouge()
        self.predictions = []
        self.ground_truths = []
        
    def setup_logging(self) -> None:
        """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
        os.makedirs(self.config.output_dir, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'{self.config.output_dir}/evaluation.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def clear_memory(self) -> None:
        """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
    
    def load_model_and_processor(self) -> None:
        """íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ"""
        try:
            self.logger.info(f"ëª¨ë¸ ë¡œë“œ ì‹œì‘: {self.config.model_path}")
            
            self.model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
                self.config.model_path,
                device_map="auto",
                torch_dtype=torch.bfloat16,
                trust_remote_code=True
            )
            
            self.processor = AutoProcessor.from_pretrained(
                self.config.model_path,
                min_pixels=self.config.min_pixels,
                max_pixels=self.config.max_pixels
            )
            
            self.model.eval()
            self.logger.info("ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def load_test_data(self) -> List[Dict]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
        try:
            if not Path(self.config.test_data_path).exists():
                raise FileNotFoundError(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.config.test_data_path}")
            
            dataset = load_dataset('json', data_files=self.config.test_data_path)
            test_data = dataset['train']
            
            if self.config.max_samples:
                test_data = test_data.select(range(min(self.config.max_samples, len(test_data))))
            
            self.logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(test_data)}ê°œ ìƒ˜í”Œ")
            return test_data
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def compute_text_metrics(self, predictions: List[str], references: List[str]) -> Dict:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ í‰ê°€ ì§€í‘œ ê³„ì‚°"""
        metrics = {}
        
        # BLEU Score
        bleu_scores = []
        smoothing = SmoothingFunction().method4
        for pred, ref in zip(predictions, references):
            pred_tokens = word_tokenize(pred.lower())
            ref_tokens = word_tokenize(ref.lower())
            bleu = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothing)
            bleu_scores.append(bleu)
        metrics['bleu'] = np.mean(bleu_scores)
        
        # ROUGE Scores
        try:
            rouge_scores = self.rouge.get_scores(predictions, references, avg=True)
            metrics['rouge-1'] = rouge_scores['rouge-1']['f']
            metrics['rouge-2'] = rouge_scores['rouge-2']['f']
            metrics['rouge-l'] = rouge_scores['rouge-l']['f']
        except Exception as e:
            self.logger.warning(f"ROUGE ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            metrics['rouge-1'] = metrics['rouge-2'] = metrics['rouge-l'] = 0.0
        
        return metrics


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='VLM ëª¨ë¸ í‰ê°€ ë° ì˜ˆì¸¡')
    parser.add_argument('--mode', type=str, default='predict_folder', 
                        choices=['evaluate', 'predict_folder'],
                        help='ì‹¤í–‰ ëª¨ë“œ ì„ íƒ')
    parser.add_argument('--model_path', type=str, 
                        default='/workspace/Toonspace_VLM/ex_models/with_previous_toptoon_data_grok/checkpoint-10000',
                        help='ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--base_model_id', type=str,
                        default='huihui-ai/Qwen2.5-VL-7B-Instruct-abliterated',
                        help='ì›ë³¸ ëª¨ë¸ ID (í”„ë¡œì„¸ì„œ ë¡œë“œìš©)')
    parser.add_argument('--image_folder', type=str,
                        default='/workspace/Toonspace_VLM/data/test_image/escape_home/01',
                        help='ì˜ˆì¸¡í•  ì´ë¯¸ì§€ í´ë” ê²½ë¡œ')
    parser.add_argument('--use_context', type=bool, default=True,
                        help='ì´ì „ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© ì—¬ë¶€')
    parser.add_argument('--output_dir', type=str, default='/workspace/Toonspace_VLM/test/output_json',
                        help='ê²°ê³¼ ì €ì¥ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    if args.mode == 'predict_folder':
        # ì›¹íˆ° í´ë” ì˜ˆì¸¡ ëª¨ë“œ
        config = WebtoonPredictConfig(
            model_path=args.model_path,
            base_model_id=args.base_model_id,
            image_folder=args.image_folder,
            output_dir=args.output_dir,
            use_previous_context=args.use_context
        )
        predictor = WebtoonSequentialPredictor(config)
        results = predictor.predict_folder()
        
        print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {args.output_dir}/sequential_predictions.json")
        print(f"ğŸ“Š ì´ {len(results)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ")
        
    elif args.mode == 'evaluate':
        # í‰ê°€ ëª¨ë“œ
        config = TestConfig(
            model_path=args.model_path
        )
        evaluator = VLMEvaluator(config)
        # í‰ê°€ ë¡œì§ì€ ê¸°ì¡´ ì½”ë“œ ì°¸ì¡°


if __name__ == "__main__":
    main()