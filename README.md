# Qwen 2.5 VL Finetuning Guide

## í™˜ê²½ ì„¤ì •

### Docker í™˜ê²½
```bash
# Docker Image
huggingface/transformers-pytorch-gpu

# ì‹¤í–‰ ëª…ë ¹
sh train_shell.sh
```

## Training Arguments ì„¤ì •

### ìµœì í™” ì„¤ì •
```python
optim="adafactor"
learning_rate=self.config.learning_rate
lr_scheduler_type="constant"
warmup_ratio=self.config.warmup_ratio
max_grad_norm=self.config.max_grad_norm
```

### ì •ë°€ë„ ì„¤ì •
```python
bf16=True
fp16=False       
bf16_full_eval=True
```

### ë¡œê¹… ë° í‰ê°€
```python
logging_steps=self.config.logging_steps
eval_steps=self.config.eval_steps
eval_strategy="steps"
save_strategy="steps"
save_steps=self.config.save_steps
metric_for_best_model="eval_loss"
greater_is_better=False
load_best_model_at_end=True
```

### ëª¨ë¸ ì €ì¥
```python
save_safetensors=True
```

### ë¶„ì‚° í•™ìŠµ (FSDP)
```python
fsdp="full_shard auto_wrap"
fsdp_config={
    "min_num_params": 0,
    "xla": False,
    "xla_fsdp_grad_ckpt": False,
    "backward_prefetch": "backward_pre",
    "forward_prefetch": False,
    "limit_all_gathers": True,
    "use_orig_params": False,
    "cpu_offload": False,
    "sync_module_states": True,  # ì¤‘ìš”: ëª¨ë“ˆ ìƒíƒœ ë™ê¸°í™”
}
ddp_find_unused_parameters=False  # FSDP ì‚¬ìš© ì‹œ False ê¶Œì¥
```

### ë°ì´í„° ì²˜ë¦¬
```python
dataloader_num_workers=1
dataset_text_field=""
dataset_kwargs={"skip_prepare_dataset": True}
```

### ë©”ëª¨ë¦¬ ìµœì í™”
```python
gradient_checkpointing_kwargs={"use_reentrant": False}
```

### ì‹¤í—˜ ì¶”ì 
```python
report_to=["wandb"]
run_name=self.config.wandb_project_name
```

### ê¸°íƒ€ ì„¤ì •
```python
local_rank=-1
```

## ì£¼ìš” íŠ¹ì§•

### ğŸš€ ì„±ëŠ¥ ìµœì í™”
- **FSDP (Fully Sharded Data Parallel)**: ëŒ€ìš©ëŸ‰ ëª¨ë¸ì˜ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë¶„ì‚° í•™ìŠµ
- **BFloat16 ì •ë°€ë„**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ ë° í•™ìŠµ ì†ë„ í–¥ìƒ
- **Gradient Checkpointing**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ê°€ ê°ì†Œ

### ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬
- **Adafactor ì˜µí‹°ë§ˆì´ì €**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì ì‘í˜• í•™ìŠµë¥ 
- **CPU Offload ë¹„í™œì„±í™”**: GPU ë©”ëª¨ë¦¬ ìµœëŒ€ í™œìš©
- **ëª¨ë“ˆ ìƒíƒœ ë™ê¸°í™”**: ë¶„ì‚° í•™ìŠµ ì‹œ ì¼ê´€ì„± ë³´ì¥

### ğŸ“Š ëª¨ë‹ˆí„°ë§
- **WandB í†µí•©**: ì‹¤ì‹œê°„ í•™ìŠµ ì§„í–‰ ìƒí™© ì¶”ì 
- **ë‹¨ê³„ë³„ í‰ê°€**: ì •ê¸°ì ì¸ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦
- **ìµœì  ëª¨ë¸ ì €ì¥**: ê²€ì¦ ì†ì‹¤ ê¸°ë°˜ ìµœì  ì²´í¬í¬ì¸íŠ¸ ë³´ì¡´

### ğŸ›¡ï¸ ì•ˆì •ì„±
- **SafeTensors í˜•ì‹**: ì•ˆì „í•œ ëª¨ë¸ ì €ì¥
- **ìƒìˆ˜ í•™ìŠµë¥ **: ì•ˆì •ì ì¸ í•™ìŠµ ì§„í–‰
- **Gradient Clipping**: í•™ìŠµ ë¶ˆì•ˆì •ì„± ë°©ì§€

## ì‚¬ìš© ë°©ë²•

1. **í™˜ê²½ ì¤€ë¹„**
   ```bash
   # Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰
   docker run --gpus all -it huggingface/transformers-pytorch-gpu
   ```

2. **í•™ìŠµ ì‹¤í–‰**
   ```bash
   sh train_shell.sh
   ```

3. **ëª¨ë‹ˆí„°ë§**
   - WandB ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤ì‹œê°„ í•™ìŠµ ìƒí™© í™•ì¸
   - ë¡œê·¸ íŒŒì¼ì„ í†µí•œ ì„¸ë¶€ ì§„í–‰ ìƒí™© ì¶”ì 

## ì£¼ì˜ì‚¬í•­

âš ï¸ **ë©”ëª¨ë¦¬ ê´€ë¦¬**
- ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ë°°ì¹˜ í¬ê¸° ì¡°ì ˆ í•„ìš”
- GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ `cpu_offload=True` ê³ ë ¤

âš ï¸ **ë°ì´í„° íƒ€ì… ì¼ê´€ì„±**
- ëª¨ë“  í…ì„œê°€ ë™ì¼í•œ dtype(bfloat16) ìœ ì§€ í•„ìš”
- ì²´í¬í¬ì¸íŠ¸ ì¬ì‹œì‘ ì‹œ dtype ê²€ì¦ í•„ìˆ˜

âš ï¸ **ë¶„ì‚° í•™ìŠµ**
- FSDP ì‚¬ìš© ì‹œ `ddp_find_unused_parameters=False` í•„ìˆ˜
- ëª¨ë“ˆ ìƒíƒœ ë™ê¸°í™” í™œì„±í™” ê¶Œì¥
